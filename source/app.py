# source/app.py

import asyncio
import sys
import time
import streamlit as st
from datetime import datetime

# --- Fix for grpc.aio "no event loop" in Streamlit ---
if sys.platform == "darwin":
    asyncio.set_event_loop_policy(asyncio.DefaultEventLoopPolicy())
try:
    asyncio.get_event_loop()
except RuntimeError:
    asyncio.set_event_loop(asyncio.new_event_loop())

# --- Cache-based timestamp store (survives refresh) ---
@st.cache_data
def get_last_crawled():
    return None  # Initially empty

@st.cache_data
def update_last_crawled():
    return datetime.now().isoformat()

# --- Page Setup ---
st.set_page_config(page_title="VNExpress RAG QA", layout="wide")
st.title("ğŸ“° VNExpress Chatbot")
st.markdown("Ask questions about the current VNExpress articles.")

# --- News Refresh Section ---
st.subheader("ğŸ•¸ï¸ VNExpress Data Update")


# Run enhanced Playwright-based crawler on button click
if st.button("ğŸ“° Get News (Playwright)"):
    from new_crawl import run as enhanced_crawl_news
    with st.spinner("ğŸ•·ï¸ Crawling VNExpress with Playwright and updating vector database..."):
        try:
            enhanced_crawl_news(use_cache=False, max_links=15, reset_collection=False)
            update_last_crawled.clear()  # Clear cache
            new_time = update_last_crawled()  # Re-cache new time
            st.success(f"âœ… News updated at `{new_time}`")
        except Exception as e:
            st.error(f"âŒ Failed to crawl news: {e}")

# --- Environment Setup ---
from config import validate_environment
from storage.qdrant_store import initialize_vectorstore
from main import retrieve_documents, generate_response_stream

validate_environment()
vectorstore, client = initialize_vectorstore()

# --- User Input ---
query = st.text_input(
    "ğŸ’¬ Ask your question:",
    placeholder="e.g. HÃ£y há»i tÃ´i vá» tin tá»©c hÃ´m nay"
)

# --- Main QA Logic ---
if query:
    with st.spinner("ğŸ” Searching..."):
        retrieval = retrieve_documents(query, vectorstore, client)

    if not retrieval["success"]:
        st.error(f"âŒ Retrieval failed: {retrieval['content']}")
    else:
        st.markdown("### ğŸ¤– Answer")
        response_placeholder = st.empty()
        full_response = ""

        for chunk in generate_response_stream(query, retrieval["content"]):
            full_response += chunk
            response_placeholder.markdown(full_response + "|")  # Blinking cursor

        response_placeholder.markdown(full_response)

        # with st.expander("ğŸ“š Retrieved Context"):
        #     st.markdown(retrieval["content"][:3000])  # Avoid overwhelming display
